# ğŸ¤– GuÃ­a de Entrenamiento de Modelo - ChurnInsight

## ğŸ¯ Objetivo

Entrenar un modelo **RandomForestClassifier** para predecir churn con alta precisiÃ³n y capacidad de generalizaciÃ³n.

## ğŸ“‹ Pipeline de Entrenamiento

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. CARGAR DATOS                                 â”‚
â”‚    â””â”€ data/dataset.csv (7000 registros)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. EXPLORACIÃ“N Y LIMPIEZA                       â”‚
â”‚    â””â”€ Chequear NaN                              â”‚
â”‚    â””â”€ Detectar outliers                         â”‚
â”‚    â””â”€ Validar ranges                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. FEATURE ENGINEERING                          â”‚
â”‚    â””â”€ Encoding categÃ³ricos (OneHotEncoder)      â”‚
â”‚    â””â”€ Scaling numÃ©ricos (StandardScaler)        â”‚
â”‚    â””â”€ Crear features derivadas                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. SPLIT TRAIN/TEST                             â”‚
â”‚    â””â”€ Train: 70% (4900 registros)               â”‚
â”‚    â””â”€ Test: 30% (2100 registros)                â”‚
â”‚    â””â”€ Random state: 42                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. ENTRENAR MODELO                              â”‚
â”‚    â””â”€ RandomForestClassifier                    â”‚
â”‚    â””â”€ n_estimators: 100                         â”‚
â”‚    â””â”€ max_depth: 15                             â”‚
â”‚    â””â”€ min_samples_split: 10                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. VALIDACIÃ“N                                   â”‚
â”‚    â””â”€ Cross-validation (5-fold)                 â”‚
â”‚    â””â”€ Metricas: Accuracy, Precision, Recall     â”‚
â”‚    â””â”€ Confusion matrix                          â”‚
â”‚    â””â”€ ROC-AUC curve                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. EVALUACIÃ“N EN TEST                           â”‚
â”‚    â””â”€ Accuracy, Precision, Recall, F1           â”‚
â”‚    â””â”€ Feature importance                        â”‚
â”‚    â””â”€ Predicciones vs Reales                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. SERIALIZAR MODELO                            â”‚
â”‚    â””â”€ models/churn_model.pkl (joblib)           â”‚
â”‚    â””â”€ VersiÃ³n: v1                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ ParÃ¡metros del Modelo

### RandomForestClassifier

```python
RandomForestClassifier(
    n_estimators=100,           # NÃºmero de Ã¡rboles
    max_depth=15,               # Profundidad mÃ¡xima
    min_samples_split=10,       # MÃ­nimo para dividir nodo
    min_samples_leaf=5,         # MÃ­nimo en hoja
    random_state=42,            # Reproducibilidad
    n_jobs=-1,                  # Usar todos los cores
    class_weight='balanced'     # Manejar desbalance
)
```

### JustificaciÃ³n de ParÃ¡metros

| ParÃ¡metro           | Valor      | RazÃ³n                                        |
| ------------------- | ---------- | -------------------------------------------- |
| `n_estimators`      | 100        | Balance entre precisiÃ³n y velocidad          |
| `max_depth`         | 15         | Evitar overfitting mientras captura patrones |
| `min_samples_split` | 10         | Evitar splits en pocos muestras              |
| `class_weight`      | 'balanced' | Manejar desbalance 70/30                     |
| `random_state`      | 42         | Reproducibilidad en producciÃ³n               |

## ğŸ“Š MÃ©tricas Esperadas

### Performance en Training

```
Accuracy:   92%
Precision:  90%
Recall:     85%
F1-Score:   87%
AUC-ROC:    0.94
```

### Performance en Test

```
Accuracy:   87%
Precision:  85%
Recall:     82%
F1-Score:   83%
AUC-ROC:    0.91
```

### Feature Importance (Top 10)

```
1. Last_Transaction_Days_Ago  38%  â­â­â­ CRÃTICO
2. Active_Days                22%  â­â­
3. Total_Transactions         18%  â­â­
4. Avg_Transaction_Value      12%  â­
5. Customer_Satisfaction      10%  â­
6. Income_Level_High          5%
7. App_Usage_Frequency_Daily  4%
8. Location_Urban             2%
...
```

## ğŸš€ CÃ³mo Entrenar

### OpciÃ³n 1: Script AutomÃ¡tico

```bash
cd data-science
python scripts/train_model.py
```

Este comando:

1. âœ… Genera dataset si no existe
2. âœ… Carga y explora datos
3. âœ… Prepara features
4. âœ… Divide train/test
5. âœ… Entrena modelo
6. âœ… EvalÃºa en test
7. âœ… Guarda como `models/churn_model.pkl`

### OpciÃ³n 2: Notebook Interactivo

```bash
cd data-science
jupyter notebook notebooks/EDA.md
```

Luego ejecutar celdas manualmente para ver cada paso.

## ğŸ“ˆ ValidaciÃ³n Cruzada

```python
from sklearn.model_selection import cross_val_score

# 5-fold cross-validation
cv_scores = cross_val_score(
    model, X_train, y_train,
    cv=5,
    scoring='roc_auc'
)

print(f"CV Scores: {cv_scores}")
print(f"Mean: {cv_scores.mean():.3f} (+/- {cv_scores.std():.3f})")
```

**Resultado esperado:**

```
Mean: 0.912 (+/- 0.045)  âœ…
```

## ğŸ” AnÃ¡lisis de Errores

### Confusion Matrix

```
                Predicho
              Churn | No Churn
Actual â”œâ”€ Churn    â”‚ 1680 â”‚ 420
       â”‚
       â””â”€ No Churn â”‚ 350  â”‚ 6550

True Positives (TP):   1680  â†’ Correctamente identificÃ³ churners
False Positives (FP):  350   â†’ Falsa alarma
False Negatives (FN):  420   â†’ Churners no detectados
True Negatives (TN):   6550  â†’ Correctamente identificÃ³ retenciones
```

### InterpretaciÃ³n

- **Precision = 1680 / (1680 + 350) = 82.7%**
  - De los que dijimos que van a irse, 82.7% realmente se van
- **Recall = 1680 / (1680 + 420) = 80.0%**
  - De los que realmente se van, detectamos 80%
- **False Positive Rate = 350 / (350 + 6550) = 5.1%**
  - Solo 5.1% de retenciones son marcadas como churn (bueno)

## âš ï¸ Problemas Comunes

### 1. Overfitting

**SÃ­ntoma:** Training 98%, Test 72%

**SoluciÃ³n:**

```python
# Aumentar min_samples_split
model = RandomForestClassifier(
    n_estimators=100,
    max_depth=12,  # Reducir
    min_samples_split=15  # Aumentar
)
```

### 2. Underfitting

**SÃ­ntoma:** Training 75%, Test 73%

**SoluciÃ³n:**

```python
# Disminuir regularizaciÃ³n
model = RandomForestClassifier(
    n_estimators=150,  # Aumentar
    max_depth=20,      # Aumentar
    min_samples_split=5  # Disminuir
)
```

### 3. Desbalance de Clases

**SÃ­ntoma:** Predice siempre 0 (no churn)

**SoluciÃ³n:**

```python
# Usar class_weight
model = RandomForestClassifier(
    class_weight='balanced',
    # o definir manualmente
    class_weight={
        0: 1.0,    # No churn
        1: 2.3     # Churn (70/30 ratio)
    }
)

# O: Oversampling de minority
from imblearn.over_sampling import SMOTE
smote = SMOTE()
X_balanced, y_balanced = smote.fit_resample(X_train, y_train)
model.fit(X_balanced, y_balanced)
```

## ğŸ”„ Reentrenamiento PeriÃ³dico

**CuÃ¡ndo reentrenar:**

1. Cada mes con datos nuevos
2. Si accuracy baja < 85%
3. Si datos cambian significativamente
4. Si deploy requiere actualizaciÃ³n

**CÃ³mo:**

```bash
# 1. Recopilar datos nuevos
SELECT * FROM transactions WHERE created_at > last_training_date

# 2. Guardar como data/dataset_new.csv

# 3. Reentrenar
python scripts/train_model.py --dataset data/dataset_new.csv

# 4. Evaluar
python scripts/evaluate_model.py

# 5. Si mejora, reemplazar
cp models/churn_model.pkl models/churn_model_backup.pkl
cp models/churn_model_new.pkl models/churn_model.pkl
```

## ğŸ“Š Logging de MÃ©tricas

El script genera `logs/training_metrics.json`:

```json
{
  "timestamp": "2025-12-27T23:00:00",
  "dataset": {
    "total_samples": 7000,
    "churn_percentage": 30.1,
    "train_samples": 4900,
    "test_samples": 2100
  },
  "model": {
    "type": "RandomForestClassifier",
    "n_estimators": 100,
    "max_depth": 15
  },
  "performance": {
    "train_accuracy": 0.9234,
    "test_accuracy": 0.8712,
    "test_precision": 0.8524,
    "test_recall": 0.8201,
    "test_f1": 0.836,
    "test_auc_roc": 0.9123
  },
  "feature_importance": {
    "Last_Transaction_Days_Ago": 0.3847,
    "Active_Days": 0.2156,
    "Total_Transactions": 0.1823
  }
}
```

## ğŸ¯ ProducciÃ³n Checklist

- âœ… Modelo serializado en `models/churn_model.pkl`
- âœ… MÃ©tricas documentadas en logs
- âœ… Feature names coinciden con `config.py`
- âœ… Accuraccy > 85% en test
- âœ… Ninguna mÃ©trica en rojo
- âœ… VersiÃ³n tagged (v1, v2, etc.)

## ğŸ“ Troubleshooting

| Error                             | Causa                  | SoluciÃ³n                            |
| --------------------------------- | ---------------------- | ----------------------------------- |
| ModuleNotFoundError: scikit-learn | Falta instalar         | `pip install scikit-learn`          |
| FileNotFoundError: dataset.csv    | Datos no generados     | `python scripts/train_model.py`     |
| MemoryError                       | Dataset muy grande     | Reducir n_samples en train_model.py |
| Low accuracy                      | Datos malos o features | Revisar EDA.md                      |

---

**Ãšltima actualizaciÃ³n:** Diciembre 2025  
**VersiÃ³n del modelo:** 1.0
