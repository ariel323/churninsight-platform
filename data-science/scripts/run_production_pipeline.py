#!/usr/bin/env python3
"""
ChurnInsight Production Pipeline - Automated Workflow

Ejecuta:
1. Generaci√≥n de datos
2. Entrenamiento de modelo
3. Validaci√≥n y despliegue

Usage:
    python run_production_pipeline.py
    python run_production_pipeline.py --skip-data     (sin regenerar datos)
    python run_production_pipeline.py --train-only    (solo entrenar)
    python run_production_pipeline.py --deploy-only   (solo desplegar)
"""

import subprocess
import sys
import json
import logging
from pathlib import Path
from datetime import datetime
import argparse

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/pipeline.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Rutas
SCRIPTS_DIR = Path(__file__).parent
PROJECT_ROOT = SCRIPTS_DIR.parent
MODELS_DIR = PROJECT_ROOT / 'models'
LOGS_DIR = PROJECT_ROOT / 'logs'
DATA_DIR = PROJECT_ROOT / 'data'

# Crear directorios si no existen
MODELS_DIR.mkdir(exist_ok=True)
LOGS_DIR.mkdir(exist_ok=True)
DATA_DIR.mkdir(exist_ok=True)


def run_command(script_name: str, description: str) -> bool:
    """Ejecuta un script Python y retorna True si es exitoso."""
    script_path = SCRIPTS_DIR / script_name
    
    logger.info(f"\n{'='*70}")
    logger.info(f"‚ñ∂Ô∏è  {description}")
    logger.info(f"{'='*70}")
    
    if not script_path.exists():
        logger.error(f"‚ùå Script no encontrado: {script_path}")
        return False
    
    try:
        result = subprocess.run(
            [sys.executable, str(script_path)],
            cwd=str(PROJECT_ROOT),
            capture_output=False,
            text=True,
            timeout=300  # 5 minutos max
        )
        
        if result.returncode == 0:
            logger.info(f"‚úÖ {description} completado exitosamente")
            return True
        else:
            logger.error(f"‚ùå {description} fall√≥ (exit code: {result.returncode})")
            return False
            
    except subprocess.TimeoutExpired:
        logger.error(f"‚ùå {description} tard√≥ demasiado (timeout)")
        return False
    except Exception as e:
        logger.error(f"‚ùå Error ejecutando {description}: {e}")
        return False


def verify_files_exist(files: dict) -> bool:
    """Verifica que archivos necesarios existan."""
    logger.info(f"\nüîç Verificando archivos...")
    all_exist = True
    
    for label, file_path in files.items():
        path = Path(file_path)
        if path.exists():
            size = path.stat().st_size / (1024 * 1024)  # MB
            logger.info(f"  ‚úÖ {label}: {path.name} ({size:.2f} MB)")
        else:
            logger.warning(f"  ‚ö†Ô∏è  {label}: NO ENCONTRADO - {path}")
            all_exist = False
    
    return all_exist


def load_metrics() -> dict:
    """Carga m√©tricas de training."""
    metrics_file = LOGS_DIR / 'training_metrics.json'
    if metrics_file.exists():
        try:
            with open(metrics_file) as f:
                return json.load(f)
        except:
            return {}
    return {}


def load_checklist() -> dict:
    """Carga checklist de despliegue."""
    checklist_file = LOGS_DIR / 'deployment_checklist.json'
    if checklist_file.exists():
        try:
            with open(checklist_file) as f:
                return json.load(f)
        except:
            return {}
    return {}


def print_summary():
    """Imprime resumen final de la ejecuci√≥n."""
    logger.info(f"\n{'='*70}")
    logger.info("üìä RESUMEN FINAL DEL PIPELINE")
    logger.info(f"{'='*70}")
    
    # Verificar archivos
    files_to_check = {
        'Dataset': DATA_DIR / 'dataset.csv',
        'Modelo': MODELS_DIR / 'churn_model.pkl',
        'M√©tricas': LOGS_DIR / 'training_metrics.json',
        'Checklist': LOGS_DIR / 'deployment_checklist.json',
    }
    
    files_status = {}
    for label, path in files_to_check.items():
        files_status[label] = path.exists()
    
    logger.info("\nüìÅ Estado de Archivos:")
    for label, exists in files_status.items():
        status = "‚úÖ" if exists else "‚ùå"
        logger.info(f"  {status} {label}")
    
    # Mostrar m√©tricas si existen
    metrics = load_metrics()
    if metrics:
        logger.info("\nüìà M√©tricas de Entrenamiento:")
        test_metrics = metrics.get('test_metrics', {})
        for key, value in test_metrics.items():
            if isinstance(value, float):
                logger.info(f"  ‚Ä¢ {key.capitalize()}: {value:.4f}")
    
    # Mostrar checklist si existe
    checklist = load_checklist()
    if checklist:
        logger.info("\n‚úÖ Validaci√≥n de Despliegue:")
        all_passed = checklist.get('all_passed', False)
        checks = checklist.get('validation_results', {})
        
        for check, passed in checks.items():
            status = "‚úÖ" if passed else "‚ùå"
            logger.info(f"  {status} {check}")
        
        final_status = "üü¢ PRODUCTION READY" if all_passed else "üî¥ VALIDATION FAILED"
        logger.info(f"\n  {final_status}")
    
    logger.info(f"\n{'='*70}")
    logger.info("üéâ Pipeline completado")
    logger.info(f"{'='*70}\n")


def main():
    parser = argparse.ArgumentParser(
        description='ChurnInsight Production Pipeline'
    )
    parser.add_argument(
        '--skip-data',
        action='store_true',
        help='Omitir generaci√≥n de datos'
    )
    parser.add_argument(
        '--train-only',
        action='store_true',
        help='Solo entrenar modelo'
    )
    parser.add_argument(
        '--deploy-only',
        action='store_true',
        help='Solo desplegar modelo'
    )
    
    args = parser.parse_args()
    
    logger.info("üöÄ Iniciando Pipeline de Producci√≥n ChurnInsight")
    logger.info(f"Timestamp: {datetime.now().isoformat()}")
    logger.info(f"Directorio: {PROJECT_ROOT}")
    
    success = True
    
    # 1. Generar datos (si no se especifica --skip-data y no es --deploy-only)
    if not args.skip_data and not args.deploy_only:
        logger.info("\nüìä FASE 1: GENERACI√ìN DE DATOS")
        if not run_command(
            'generate_synthetic_data.py',
            'Generaci√≥n de dataset sint√©tico'
        ):
            success = False
            logger.error("‚ùå No se puede continuar sin datos")
            return False
        
        # Verificar que se cre√≥ el dataset
        if not (DATA_DIR / 'dataset.csv').exists():
            logger.error("‚ùå Dataset no fue creado correctamente")
            return False
    
    # 2. Entrenar modelo (si no es --deploy-only)
    if not args.deploy_only:
        logger.info("\nü§ñ FASE 2: ENTRENAMIENTO DEL MODELO")
        
        # Verificar dataset
        if not (DATA_DIR / 'dataset.csv').exists():
            logger.error("‚ùå Dataset no encontrado. Ejecuta sin --train-only primero")
            return False
        
        if not run_command(
            'train_model_final.py',
            'Entrenamiento del modelo de churn'
        ):
            success = False
            logger.error("‚ùå No se puede continuar sin modelo entrenado")
            return False
        
        # Verificar que se cre√≥ el modelo
        if not (MODELS_DIR / 'churn_model.pkl').exists():
            logger.error("‚ùå Modelo no fue creado correctamente")
            return False
    
    # 3. Desplegar modelo (si no es --train-only)
    if not args.train_only:
        logger.info("\nüöÄ FASE 3: VALIDACI√ìN Y DESPLIEGUE")
        
        # Verificar archivo del modelo
        if not (MODELS_DIR / 'churn_model.pkl').exists():
            logger.error("‚ùå Modelo no encontrado. Entrena primero")
            return False
        
        if not run_command(
            'deploy_model.py',
            'Validaci√≥n y despliegue del modelo'
        ):
            success = False
            logger.error("‚ùå Despliegue fall√≥")
            return False
    
    # Resumen final
    print_summary()
    
    if success:
        logger.info("‚úÖ PIPELINE COMPLETADO EXITOSAMENTE")
        return True
    else:
        logger.error("‚ùå PIPELINE COMPLETADO CON ERRORES")
        return False


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
