# Data Science - ChurnInsight

Esta carpeta contiene todo el trabajo de ciencia de datos: exploraciÃ³n, entrenamiento y artefactos del modelo de predicciÃ³n de churn.

## ðŸš€ Inicio RÃ¡pido

### 1. Configurar el entorno

```bash
# Crear entorno virtual
python -m venv venv

# Activar entorno (Windows)
venv\Scripts\activate

# Activar entorno (Linux/Mac)
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt
```

### 2. Explorar los datos

```bash
jupyter notebook notebooks/01_exploracion_datos.ipynb
```

### 3. Entrenar el modelo

```bash
# Desde notebooks
jupyter notebook notebooks/02_entrenamiento_modelo.ipynb

# O desde scripts
python scripts/train.py --data data/dataset.csv --output model/modelo_churn.joblib
```

## ðŸ“ Estructura del Proyecto

```
data-science/
â”œâ”€â”€ README.md                          # Este archivo
â”œâ”€â”€ requirements.txt                   # Dependencias de Python
â”œâ”€â”€ data/                              # Datasets (no subir a git si son grandes)
â”‚   â””â”€â”€ .gitkeep
â”œâ”€â”€ notebooks/                         # Notebooks de Jupyter
â”‚   â”œâ”€â”€ 01_exploracion_datos.ipynb    # AnÃ¡lisis exploratorio
â”‚   â””â”€â”€ 02_entrenamiento_modelo.ipynb # Entrenamiento del modelo
â”œâ”€â”€ scripts/                           # Scripts de Python reutilizables
â”‚   â”œâ”€â”€ train.py                       # Script de entrenamiento
â”‚   â””â”€â”€ predict.py                     # Script de predicciÃ³n
â””â”€â”€ model/                             # Modelos entrenados (.joblib, .pkl, .h5, etc.)
    â”œâ”€â”€ .gitkeep
    â””â”€â”€ MODEL_INFO.md                  # DocumentaciÃ³n del modelo
```

## ðŸ“Š Flujo de Trabajo

1. **ExploraciÃ³n de Datos**: Usar `01_exploracion_datos.ipynb` para entender el dataset
2. **Feature Engineering**: DiseÃ±ar y crear features relevantes
3. **Entrenamiento**: Entrenar modelos usando `02_entrenamiento_modelo.ipynb` o `scripts/train.py`
4. **EvaluaciÃ³n**: Comparar mÃ©tricas (accuracy, precision, recall, ROC-AUC)
5. **ExportaciÃ³n**: Guardar el mejor modelo en formato `.joblib` (o `.pkl`) en la carpeta `model/`
6. **IntegraciÃ³n**: El backend Java cargarÃ¡ el modelo para hacer predicciones

## ðŸ”§ Scripts Disponibles

### train.py

Entrena el modelo de predicciÃ³n de churn.

```bash
python scripts/train.py --data data/dataset.csv --output model/churn_model.pkl --test-size 0.2
```

### predict.py

Realiza predicciones usando un modelo entrenado.

```bash
python scripts/predict.py --model model/churn_model.pkl --input data/nuevos_clientes.csv --output predictions.csv
```

## ðŸ“ˆ MÃ©tricas Objetivo

- **MÃ©trica principal**: ROC-AUC Score
- **MÃ©tricas secundarias**: Precision, Recall, F1-Score
- **Umbral de producciÃ³n**: ROC-AUC > 0.75

## ðŸ“ DocumentaciÃ³n de Modelos

Cuando entrenes un modelo, documenta:

- **Features utilizadas**: Lista completa de variables
- **VersiÃ³n de datos**: Fecha y fuente del dataset
- **HiperparÃ¡metros**: ConfiguraciÃ³n del modelo
- **MÃ©tricas obtenidas**: Resultados de evaluaciÃ³n
- **Fecha de entrenamiento**: CuÃ¡ndo se entrenÃ³

Ejemplo: Crear un archivo `model/modelo_v1_info.txt` con esta informaciÃ³n.

## âš ï¸ Buenas PrÃ¡cticas

- âœ… **Versionar cÃ³digo**, no datos grandes ni modelos pesados
- âœ… Usar `.gitignore` para excluir datasets crudos y modelos grandes
- âœ… Documentar cada experimento en los notebooks
- âœ… Mantener scripts actualizados y funcionales
- âœ… Usar semillas aleatorias (`random_state`) para reproducibilidad
- âŒ No subir archivos `.csv` o `.pkl` > 10 MB sin acordarlo con el equipo

## ðŸ”— IntegraciÃ³n con Backend

El modelo entrenado se exporta en formato `.pkl` (pickle) y el backend Java lo consumirÃ¡ a travÃ©s de:

- API REST para predicciones en tiempo real
- Carga del modelo usando Jython o servicios externos (Python microservice)
